{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://tva1.sinaimg.cn/large/007S8ZIlgy1ger772p2t6j318c0t6gwl.jpg' width='30%'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T14:21:53.117520Z",
     "start_time": "2020-05-13T14:21:53.111050Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import sys; sys.path.insert(0, '../')\n",
    "from exp import nb_d2l_utils\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T14:21:53.915499Z",
     "start_time": "2020-05-13T14:21:53.910319Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "# torch.cuda.manual_seed_all(0)\n",
    "\n",
    "torch.__version__               # PyTorch version\n",
    "# torch.version.cuda              # Corresponding CUDA version\n",
    "# torch.backends.cudnn.version()  # Corresponding cuDNN version\n",
    "# torch.cuda.get_device_name(0)   # GPU type\n",
    "\n",
    "dev = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T14:22:19.542467Z",
     "start_time": "2020-05-13T14:22:19.346448Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 1, 28, 28]), torch.Size([16]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    # you can add other transformations in this list\n",
    "    transforms.Resize((28,28)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_data = torchvision.datasets.FashionMNIST('path/to/imagenet_root/', transform=transform, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                          batch_size=16,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=4)\n",
    "\n",
    "vali_data = torchvision.datasets.FashionMNIST('path/to/imagenet_root/', train=False, transform=transform, download=True)\n",
    "vali_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                          batch_size=16,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=4)\n",
    "            \n",
    "X, y = iter(train_loader).next()\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T14:22:21.504898Z",
     "start_time": "2020-05-13T14:22:21.488646Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "import re\n",
    "import typing\n",
    "from collections import namedtuple\n",
    "import torch\n",
    "\n",
    "_camel_re1 = re.compile('(.)([A-Z][a-z]+)')\n",
    "_camel_re2 = re.compile('([a-z0-9])([A-Z])')\n",
    "\n",
    "class CancelTrainException(Exception): pass\n",
    "class CancelEpochException(Exception): pass\n",
    "class CancelBatchException(Exception): pass\n",
    "\n",
    "def camel2snake(name):\n",
    "    s1 = re.sub(_camel_re1, r'\\1_\\2', name)\n",
    "    return re.sub(_camel_re2, r'\\1_\\2', s1).lower()\n",
    "\n",
    "\n",
    "def listify(o):\n",
    "    if o is None: return []\n",
    "    if isinstance(o, list): return o\n",
    "    if isinstance(o, str): return [o]\n",
    "    if isinstance(o, typing.Iterable): return list(o)\n",
    "    return [o]\n",
    "\n",
    "\n",
    "class Runner():\n",
    "    \"\"\"\n",
    "    begin_fit\n",
    "        begin_epoch\n",
    "            begin_batch\n",
    "            after_pred\n",
    "            after_loss\n",
    "            after_backward\n",
    "            after_step\n",
    "            after_batch\n",
    "        begin_validate\n",
    "            begin_batch\n",
    "            after_pred\n",
    "            after_loss\n",
    "            after_backward\n",
    "            after_step\n",
    "            after_batch\n",
    "        after_epoch\n",
    "    after_fit\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cbs=None, cb_funcs=None):\n",
    "        cbs = listify(cbs)\n",
    "        for cbf in listify(cb_funcs):\n",
    "            cb = cbf()\n",
    "            setattr(self, cb.name, cb)\n",
    "            cbs.append(cb)\n",
    "        self.stop = False\n",
    "        self.cbs = [TrainEvalCallback()] + cbs\n",
    "\n",
    "    @property\n",
    "    def opt(self):\n",
    "        return self.learn.opt\n",
    "\n",
    "    @property\n",
    "    def model(self):\n",
    "        return self.learn.model\n",
    "\n",
    "    @property\n",
    "    def loss_func(self):\n",
    "        return self.learn.loss_func\n",
    "\n",
    "    @property\n",
    "    def data(self):\n",
    "        return self.learn.data\n",
    "\n",
    "    def one_batch(self, xb, yb):\n",
    "        try:\n",
    "            self.xb,self.yb = xb,yb\n",
    "            self('begin_batch')\n",
    "            self.pred = self.model(self.xb)\n",
    "            self('after_pred')\n",
    "            self.loss = self.loss_func(self.pred, self.yb)\n",
    "            self('after_loss')\n",
    "            if not self.in_train: return\n",
    "            self.loss.backward()\n",
    "            self('after_backward')\n",
    "            self.opt.step()\n",
    "            self('after_step')\n",
    "            self.opt.zero_grad()\n",
    "        except CancelBatchException: self('after_cancel_batch')\n",
    "        finally: self('after_batch')\n",
    "        \n",
    "\n",
    "    def all_batches(self, dl):\n",
    "        self.iters = len(dl)  # howmany batches in one epoch\n",
    "        try:\n",
    "            for xb,yb in dl: \n",
    "                if self.stop: break\n",
    "                self.one_batch(xb, yb)\n",
    "        except CancelEpochException: self('after_cancel_epoch')\n",
    "        finally:\n",
    "            self.stop = False\n",
    "\n",
    "    def fit(self, epochs, learn):\n",
    "        self.epochs, self.learn = epochs, learn\n",
    "\n",
    "        try:\n",
    "            for cb in self.cbs: cb.set_runner(self)\n",
    "            if self('begin_fit'): return\n",
    "            for epoch in range(epochs):\n",
    "                self.epoch = epoch\n",
    "                if not self('begin_epoch'):  # through every callback's begin_epoch function\n",
    "                    self.all_batches(self.data.train_dl)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    if not self('begin_validate'): \n",
    "                        self.all_batches(self.data.valid_dl)\n",
    "                if self('after_epoch'): break\n",
    "        except CancelTrainException: self('after_cancel_fit')\n",
    "        finally:\n",
    "            self('after_fit')\n",
    "            self.learn = None\n",
    "\n",
    "    def __call__(self, cb_name):\n",
    "        res = False\n",
    "        for cb in sorted(self.cbs, key=lambda x: x._order): \n",
    "            res = cb(cb_name) or res\n",
    "        return res\n",
    "\n",
    "\n",
    "class Callback:\n",
    "    _order = 0\n",
    "    def set_runner(self, run): self.run = run\n",
    "    def __getattr__(self, k): return getattr(self.run, k)\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        name = re.sub(r'Callback$', '', self.__class__.__name__)\n",
    "        return camel2snake(name or 'callback')\n",
    "    \n",
    "    def __call__(self, cb_name):\n",
    "        f = getattr(self, cb_name, None)\n",
    "        if f and f(): return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import time\n",
    "class TrainEvalCallback(Callback):\n",
    "    def begin_fit(self):\n",
    "        self.run.n_epochs = 0.\n",
    "        self.run.n_iter = 0\n",
    "\n",
    "    def begin_epoch(self):\n",
    "        self.run.n_epochs = self.epoch\n",
    "        self.model.train()\n",
    "        self.run.in_train = True\n",
    "\n",
    "    def after_batch(self):\n",
    "        if not self.in_train:\n",
    "            return\n",
    "        self.run.n_epochs += 1. / self.iters\n",
    "        self.run.n_iter += 1\n",
    "\n",
    "    def begin_validate(self):\n",
    "        self.model.eval()\n",
    "        self.run.in_train = False\n",
    "\n",
    "\n",
    "class AvgStats():\n",
    "    def __init__(self, metrics, in_train):\n",
    "        self.metrics, self.in_train = listify(metrics), in_train\n",
    "\n",
    "    def reset(self):\n",
    "        self.tot_loss, self.count = 0., 0\n",
    "        self.tot_mets = [0.] * len(self.metrics)\n",
    "\n",
    "    @property\n",
    "    def all_stats(self):\n",
    "        return [self.tot_loss.item()] + [i.item() for i in self.tot_mets]\n",
    "\n",
    "    @property\n",
    "    def avg_stats(self):\n",
    "        return [o / self.count for o in self.all_stats]\n",
    "\n",
    "    def __repr__(self):\n",
    "        if not self.count: return \"\"\n",
    "        return f\"{'train' if self.in_train else 'valid'}: {self.avg_stats}\"\n",
    "\n",
    "    def accumulate(self, run):\n",
    "        bn = run.xb.shape[0]\n",
    "        self.tot_loss += run.loss * bn\n",
    "        self.count += bn\n",
    "        for i, m in enumerate(self.metrics):\n",
    "            self.tot_mets[i] += m(run.pred, run.yb) * bn\n",
    "\n",
    "\n",
    "class AvgStatsCallback(Callback):\n",
    "    def __init__(self, metrics, need_time=True):\n",
    "        self.train_stats = AvgStats(metrics, True)\n",
    "        self.valid_stats = AvgStats(metrics, False)\n",
    "        self.need_time = need_time\n",
    "\n",
    "    def begin_epoch(self):\n",
    "        self.train_stats.reset()\n",
    "        self.valid_stats.reset()\n",
    "        self.run.epoch_ts = time.time()\n",
    "\n",
    "    def after_loss(self):\n",
    "        stats = self.train_stats if self.in_train else self.valid_stats\n",
    "        with torch.no_grad():\n",
    "            stats.accumulate(self.run)\n",
    "\n",
    "    def after_epoch(self):\n",
    "        self.run.epoch_ts = time.time() - self.run.epoch_ts\n",
    "        time_str = f\"{self.run.epoch_ts:.1f} sec\" if self.need_time and self.run.epoch_ts else ''\n",
    "        print(f\"epoch {self.epoch+1}: {self.train_stats} {self.valid_stats} {time_str}\")\n",
    "\n",
    "        \n",
    "class RecordCallback(Callback):\n",
    "    def begin_fit(self):\n",
    "        self.lrs = []\n",
    "        self.losses = []\n",
    "    \n",
    "    def after_batch(self):\n",
    "        self.lrs.append(self.opt.param_groups[-1]['lr'])\n",
    "        self.losses.append(self.loss.detach().cpu())\n",
    "        \n",
    "\n",
    "class CudaCallback(Callback):\n",
    "    def __init__(self,device): \n",
    "        self.device=device\n",
    "        \n",
    "    def begin_fit(self): \n",
    "        self.model.to(self.device)\n",
    "        \n",
    "    def begin_batch(self): \n",
    "        self.run.xb = self.xb.to(self.device)\n",
    "        self.run.yb = self.yb.to(self.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T14:22:21.660232Z",
     "start_time": "2020-05-13T14:22:21.649880Z"
    }
   },
   "outputs": [],
   "source": [
    "class MnistLinear(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = torch.nn.Linear(784, 64)\n",
    "        self.linear2 = torch.nn.Linear(64, 10)\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        xb = xb.view(-1,28*28)\n",
    "        xb = self.linear1(xb).relu_()\n",
    "        xb = self.linear2(xb).relu_()\n",
    "        return xb\n",
    "    \n",
    "class Learner():\n",
    "    def __init__(self, model, opt, loss_func, data):\n",
    "        self.model, self.opt, self.loss_func, self.data = model, opt, loss_func, data\n",
    "\n",
    "\n",
    "def accuracy(out, yb): return (torch.argmax(out, dim=1) == yb).float().mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T14:22:21.790962Z",
     "start_time": "2020-05-13T14:22:21.785833Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: train: [1.0468716796875, 0.6301] valid: [1.0063274088541667, 0.65785] 29.9 sec\n",
      "epoch 2: train: [0.9899589192708333, 0.6446] valid: [0.9982610026041666, 0.6415833333333333] 21.6 sec\n",
      "epoch 3: train: [0.9767511067708333, 0.6476833333333334] valid: [0.9547477213541666, 0.6434166666666666] 24.5 sec\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "model = MnistLinear()\n",
    "learn = Learner(\n",
    "    model=model,\n",
    "    opt=torch.optim.Adam(model.parameters(), lr=1e-2),\n",
    "    loss_func=torch.nn.CrossEntropyLoss(),\n",
    "    data=namedtuple('data', ['train_dl', 'valid_dl'])(train_loader, vali_loader),\n",
    ")\n",
    "\n",
    "cbs = [\n",
    "    partial(AvgStatsCallback, accuracy),\n",
    "    RecordCallback\n",
    "]\n",
    "runner = Runner(cb_funcs=cbs)\n",
    "runner.fit(3, learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted [Advanced] CallBack.ipynb to exp/callback.py\n",
      "__init__.py     \u001b[1m\u001b[36m__pycache__\u001b[m\u001b[m     callback.py     nb_d2l_utils.py\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['AvgStats',\n",
       " 'AvgStatsCallback',\n",
       " 'Callback',\n",
       " 'CancelBatchException',\n",
       " 'CancelEpochException',\n",
       " 'CancelTrainException',\n",
       " 'CudaCallback',\n",
       " 'RecordCallback',\n",
       " 'Runner',\n",
       " 'TrainEvalCallback',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " '_camel_re1',\n",
       " '_camel_re2',\n",
       " 'camel2snake',\n",
       " 'listify',\n",
       " 'namedtuple',\n",
       " 're',\n",
       " 'time',\n",
       " 'torch',\n",
       " 'typing']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!python notebook2script.py [Advanced]\\ CallBack.ipynb callback.py\n",
    "!ls exp\n",
    "\n",
    "import sys; sys.path.insert(0, '../')\n",
    "from exp import callback\n",
    "\n",
    "dir(callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_torch_kernel",
   "language": "python",
   "name": "py3_torch_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
