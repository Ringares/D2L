{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchviz\n",
    "import sys; sys.path.insert(0, '../')\n",
    "from exp import nb_d2l_utils, callback\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturesLinear(torch.nn.Module):\n",
    "    def __init__(self, field_dims, output_dim=1):\n",
    "        \"\"\"\n",
    "        用一维 embedding 模拟线性函数\n",
    "        计算每个特征对应的 offset 起始位置\n",
    "        :param field_dims:\n",
    "        :param output_dim:\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.fc = torch.nn.Embedding(sum(field_dims), output_dim)\n",
    "        self.bias = torch.nn.Parameter(torch.zeros((output_dim,)))\n",
    "        self.offsets = np.array((0, *np.cumsum(field_dims)[:-1]), dtype=np.long)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        输入是 特征的 labeled index\n",
    "        :param x: Long tensor of size ``(batch_size, num_fields)``\n",
    "        \"\"\"\n",
    "        x = x + x.new_tensor(self.offsets).unsqueeze(0)\n",
    "        return torch.sum(self.fc(x), dim=1) + self.bias\n",
    "\n",
    "\n",
    "class FeaturesEmbedding(torch.nn.Module):\n",
    "    def __init__(self, field_dims, embed_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = torch.nn.Embedding(sum(field_dims), embed_dim)\n",
    "        self.offsets = np.array((0, *np.cumsum(field_dims)[:-1]), dtype=np.long)\n",
    "        torch.nn.init.xavier_uniform_(self.embedding.weight.data)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: Long tensor of size ``(batch_size, num_fields)``\n",
    "        \"\"\"\n",
    "        x = x + x.new_tensor(self.offsets).unsqueeze(0)\n",
    "        return self.embedding(x)\n",
    "\n",
    "\n",
    "class FactorizationMachine(torch.nn.Module):\n",
    "    def __init__(self, reduce_sum=True):\n",
    "        super().__init__()\n",
    "        self.reduce_sum = reduce_sum\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: Float tensor of size ``(batch_size, num_fields, embed_dim)``\n",
    "        \"\"\"\n",
    "        square_of_sum = torch.sum(x, dim=1) ** 2\n",
    "        sum_of_square = torch.sum(x ** 2, dim=1)\n",
    "        ix = square_of_sum - sum_of_square\n",
    "        if self.reduce_sum:\n",
    "            ix = torch.sum(ix, dim=1, keepdim=True)\n",
    "        return 0.5 * ix\n",
    "\n",
    "\n",
    "class MultiLayerPerceptron(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims, dropout, batch_norm=False, output_layer=True):\n",
    "        super().__init__()\n",
    "        layers = list()\n",
    "        for embed_dim in hidden_dims:\n",
    "            layers.append(torch.nn.Linear(input_dim, embed_dim))\n",
    "            if batch_norm:\n",
    "                layers.append(torch.nn.BatchNorm1d(embed_dim))\n",
    "            layers.append(torch.nn.ReLU())\n",
    "            layers.append(torch.nn.Dropout(p=dropout))\n",
    "            input_dim = embed_dim\n",
    "        if output_layer:\n",
    "            layers.append(torch.nn.Linear(input_dim, 1))\n",
    "        self.mlp = torch.nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: Float tensor of size ``(batch_size, num_fields, embed_dim)``\n",
    "        \"\"\"\n",
    "        return self.mlp(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation of Wide&Deep\n",
    "\n",
    "    Reference:\n",
    "        HT Cheng, et al. Wide & Deep Learning for Recommender Systems, 2016.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, field_dims, embed_dim, hidden_dims, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = FeaturesEmbedding(field_dims, embed_dim)\n",
    "        self.linear = FeaturesLinear(field_dims)\n",
    "        self.concat_embed_dim = len(field_dims) * embed_dim\n",
    "        self.mlp = MultiLayerPerceptron(self.concat_embed_dim, hidden_dims, dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # wide\n",
    "        y_linear = self.linear(x)\n",
    "        # deep\n",
    "        embed = self.embedding(x)\n",
    "        y_mlp = self.mlp(embed.view(-1, self.concat_embed_dim))\n",
    "        \n",
    "        y = y_linear + y_mlp\n",
    "        return torch.sigmoid(y.squeeze(1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_dims = [100]*10\n",
    "model = WideAndDeepModel(field_dims, 8, [16, 16], 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5468], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.randint(0, 100, (1,10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>unknown</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>...</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>49</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>55105</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>39</td>\n",
       "      <td>F</td>\n",
       "      <td>executive</td>\n",
       "      <td>00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>25</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>40206</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>28</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>80525</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>47</td>\n",
       "      <td>M</td>\n",
       "      <td>educator</td>\n",
       "      <td>55113</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  age gender  occupation zipcode  unknown  Action  \\\n",
       "0      196      242   49      M      writer   55105        0       0   \n",
       "1      186      302   39      F   executive   00000        0       0   \n",
       "2       22      377   25      M      writer   40206        0       0   \n",
       "3      244       51   28      M  technician   80525        0       0   \n",
       "4      166      346   47      M    educator   55113        0       0   \n",
       "\n",
       "   Adventure  Animation  ...  Fantasy  Film-Noir  Horror  Musical  Mystery  \\\n",
       "0          0          0  ...        0          0       0        0        0   \n",
       "1          0          0  ...        0          1       0        0        1   \n",
       "2          0          0  ...        0          0       0        0        0   \n",
       "3          0          0  ...        0          0       0        0        0   \n",
       "4          0          0  ...        0          0       0        0        0   \n",
       "\n",
       "   Romance  Sci-Fi  Thriller  War  Western  \n",
       "0        0       0         0    0        0  \n",
       "1        0       0         1    0        0  \n",
       "2        0       0         0    0        0  \n",
       "3        1       0         0    1        1  \n",
       "4        0       0         0    0        0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/ml-100k-joined.csv')\n",
    "used_feature = ['user_id', 'item_id', 'rating', \n",
    "                'age', 'gender', 'occupation', 'zipcode', \n",
    "                'unknown', 'Action', 'Adventure', 'Animation', 'Children\\'s', \n",
    "                'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy',\n",
    "                'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', \n",
    "                'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "\n",
    "data = data[used_feature]\n",
    "target = data.pop('rating')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'55105': 539,\n",
       "         '00000': 129,\n",
       "         '40206': 128,\n",
       "         '80525': 678,\n",
       "         '55113': 219,\n",
       "         '01581': 127,\n",
       "         '17110': 92,\n",
       "         '22903': 385,\n",
       "         '94086': 271,\n",
       "         '98101': 211,\n",
       "         '97214': 232,\n",
       "         '15217': 288,\n",
       "         '93402': 216,\n",
       "         '03060': 132,\n",
       "         '43512': 141,\n",
       "         '14853': 484,\n",
       "         '22206': 81,\n",
       "         '02154': 342,\n",
       "         '44106': 296,\n",
       "         '94702': 480,\n",
       "         '67401': 181,\n",
       "         'L9G2B': 69,\n",
       "         '63108': 448,\n",
       "         '95076': 397,\n",
       "         '10707': 278,\n",
       "         '54467': 121,\n",
       "         '30220': 216,\n",
       "         '75240': 93,\n",
       "         '66215': 120,\n",
       "         '52245': 24,\n",
       "         '55439': 275,\n",
       "         '58202': 27,\n",
       "         '93550': 150,\n",
       "         '98006': 264,\n",
       "         '70808': 51,\n",
       "         '21218': 493,\n",
       "         '30033': 23,\n",
       "         '95064': 518,\n",
       "         '91344': 473,\n",
       "         '90703': 184,\n",
       "         '92629': 68,\n",
       "         'E2A4H': 386,\n",
       "         '31211': 62,\n",
       "         '28734': 195,\n",
       "         '31404': 20,\n",
       "         '84103': 161,\n",
       "         '63129': 136,\n",
       "         '49512': 320,\n",
       "         '85032': 77,\n",
       "         '89801': 24,\n",
       "         '55107': 78,\n",
       "         '08403': 382,\n",
       "         '73034': 137,\n",
       "         '89503': 211,\n",
       "         '17870': 183,\n",
       "         '94703': 124,\n",
       "         '95660': 48,\n",
       "         '29206': 636,\n",
       "         '53211': 173,\n",
       "         '06472': 208,\n",
       "         '84010': 106,\n",
       "         '47906': 105,\n",
       "         '95014': 187,\n",
       "         '60201': 137,\n",
       "         '20001': 23,\n",
       "         '42647': 159,\n",
       "         '60804': 388,\n",
       "         '73439': 23,\n",
       "         '27502': 387,\n",
       "         '83716': 185,\n",
       "         '30329': 181,\n",
       "         '05201': 59,\n",
       "         '15610': 42,\n",
       "         '85251': 434,\n",
       "         'V3N4P': 316,\n",
       "         '55369': 147,\n",
       "         '38401': 55,\n",
       "         '78741': 363,\n",
       "         '78155': 300,\n",
       "         '02215': 320,\n",
       "         '95110': 122,\n",
       "         '22932': 278,\n",
       "         '84601': 46,\n",
       "         '55414': 1103,\n",
       "         '80127': 69,\n",
       "         '77840': 133,\n",
       "         '52246': 154,\n",
       "         '63146': 48,\n",
       "         '71457': 400,\n",
       "         '20009': 878,\n",
       "         '46260': 338,\n",
       "         '90064': 120,\n",
       "         '22902': 832,\n",
       "         '78264': 160,\n",
       "         '52302': 177,\n",
       "         '20854': 221,\n",
       "         '43201': 323,\n",
       "         '48823': 46,\n",
       "         '20003': 308,\n",
       "         '55345': 126,\n",
       "         '99603': 74,\n",
       "         '76111': 215,\n",
       "         '11217': 215,\n",
       "         '22904': 34,\n",
       "         '22207': 27,\n",
       "         '02138': 20,\n",
       "         '19422': 328,\n",
       "         '15213': 175,\n",
       "         '52241': 29,\n",
       "         '80521': 38,\n",
       "         '37212': 277,\n",
       "         '21044': 107,\n",
       "         '60115': 353,\n",
       "         '39042': 207,\n",
       "         '85711': 296,\n",
       "         '97301': 273,\n",
       "         '92037': 230,\n",
       "         '99709': 166,\n",
       "         '55104': 277,\n",
       "         '97006': 65,\n",
       "         '22202': 182,\n",
       "         '44133': 155,\n",
       "         '53706': 408,\n",
       "         '48103': 746,\n",
       "         '66315': 65,\n",
       "         '10309': 140,\n",
       "         '01913': 98,\n",
       "         '92110': 150,\n",
       "         '93117': 20,\n",
       "         '60067': 131,\n",
       "         '55106': 146,\n",
       "         '50325': 196,\n",
       "         '98682': 110,\n",
       "         '11231': 194,\n",
       "         '90840': 35,\n",
       "         '90254': 59,\n",
       "         '55454': 296,\n",
       "         '98103': 192,\n",
       "         '49931': 121,\n",
       "         '95032': 51,\n",
       "         '92064': 95,\n",
       "         '43212': 87,\n",
       "         '06513': 53,\n",
       "         '20008': 54,\n",
       "         '27606': 173,\n",
       "         '77904': 21,\n",
       "         '48197': 384,\n",
       "         '16803': 147,\n",
       "         '27510': 24,\n",
       "         '53703': 51,\n",
       "         '29379': 72,\n",
       "         '63119': 138,\n",
       "         '16801': 56,\n",
       "         '30067': 163,\n",
       "         '05146': 67,\n",
       "         '76013': 251,\n",
       "         '60613': 46,\n",
       "         '78602': 26,\n",
       "         '63033': 93,\n",
       "         '55337': 206,\n",
       "         '55108': 184,\n",
       "         '20784': 24,\n",
       "         '20910': 206,\n",
       "         '95161': 27,\n",
       "         '30040': 21,\n",
       "         '48118': 113,\n",
       "         '19104': 115,\n",
       "         '32301': 63,\n",
       "         '30068': 179,\n",
       "         '75094': 118,\n",
       "         '80236': 25,\n",
       "         '60202': 63,\n",
       "         '53214': 124,\n",
       "         '55346': 230,\n",
       "         '55423': 234,\n",
       "         '43202': 200,\n",
       "         '75013': 48,\n",
       "         '95628': 159,\n",
       "         '16125': 86,\n",
       "         '84408': 47,\n",
       "         '77005': 57,\n",
       "         '90630': 24,\n",
       "         '53713': 32,\n",
       "         '75206': 56,\n",
       "         '97232': 143,\n",
       "         '41850': 66,\n",
       "         '20685': 146,\n",
       "         '22973': 94,\n",
       "         '80123': 107,\n",
       "         '06059': 26,\n",
       "         '33884': 175,\n",
       "         '07039': 30,\n",
       "         '50233': 48,\n",
       "         '15237': 30,\n",
       "         '14476': 133,\n",
       "         '20015': 45,\n",
       "         '01080': 21,\n",
       "         '23226': 75,\n",
       "         '68767': 262,\n",
       "         '11727': 76,\n",
       "         '03755': 55,\n",
       "         '08816': 79,\n",
       "         '55109': 22,\n",
       "         '20057': 22,\n",
       "         '61801': 157,\n",
       "         '90210': 270,\n",
       "         '55305': 53,\n",
       "         '78750': 28,\n",
       "         '60466': 22,\n",
       "         '92103': 50,\n",
       "         '73132': 32,\n",
       "         '22306': 43,\n",
       "         '97403': 48,\n",
       "         '02139': 174,\n",
       "         '29440': 112,\n",
       "         '12550': 66,\n",
       "         '73071': 294,\n",
       "         '53715': 30,\n",
       "         '01720': 98,\n",
       "         '94043': 119,\n",
       "         '06371': 22,\n",
       "         '37235': 56,\n",
       "         '23112': 20,\n",
       "         '83814': 340,\n",
       "         '08360': 37,\n",
       "         '36117': 107,\n",
       "         '93555': 300,\n",
       "         '63130': 33,\n",
       "         '07102': 25,\n",
       "         '07029': 83,\n",
       "         '68106': 76,\n",
       "         '32250': 21,\n",
       "         '95938': 59,\n",
       "         '94533': 165,\n",
       "         '06355': 28,\n",
       "         '60035': 262,\n",
       "         '60615': 24,\n",
       "         '17325': 36,\n",
       "         '07030': 63,\n",
       "         '55125': 64,\n",
       "         '02110': 223,\n",
       "         '21911': 38,\n",
       "         '60641': 23,\n",
       "         '78205': 22,\n",
       "         '08832': 20,\n",
       "         '17604': 40,\n",
       "         '55406': 251,\n",
       "         '53115': 64,\n",
       "         '08043': 245,\n",
       "         '97365': 35,\n",
       "         '20755': 67,\n",
       "         '43537': 24,\n",
       "         '71701': 26,\n",
       "         '32067': 54,\n",
       "         '60659': 58,\n",
       "         '07733': 21,\n",
       "         '61401': 25,\n",
       "         '91711': 46,\n",
       "         '42459': 25,\n",
       "         '02143': 20,\n",
       "         '42141': 20,\n",
       "         '98034': 38,\n",
       "         '16509': 23,\n",
       "         '10960': 217,\n",
       "         '18301': 87,\n",
       "         '10003': 736,\n",
       "         '77009': 75,\n",
       "         '06518': 174,\n",
       "         '55436': 43,\n",
       "         '06260': 26,\n",
       "         '46538': 27,\n",
       "         '94619': 27,\n",
       "         '85710': 33,\n",
       "         '85202': 27,\n",
       "         '11701': 21,\n",
       "         '01002': 22,\n",
       "         '20770': 26,\n",
       "         '55413': 125,\n",
       "         '78756': 23,\n",
       "         'T8H1N': 174,\n",
       "         '44124': 29,\n",
       "         '22030': 23,\n",
       "         '19149': 89,\n",
       "         '60402': 201,\n",
       "         '32605': 37,\n",
       "         '90291': 27,\n",
       "         '06405': 51,\n",
       "         '27514': 318,\n",
       "         '77801': 23,\n",
       "         '22003': 21,\n",
       "         '24060': 154,\n",
       "         '15235': 187,\n",
       "         '11101': 284,\n",
       "         '27708': 53,\n",
       "         '06779': 283,\n",
       "         '50613': 94,\n",
       "         '30030': 25,\n",
       "         '40504': 183,\n",
       "         '46005': 23,\n",
       "         '08904': 24,\n",
       "         '97212': 23,\n",
       "         'V0R2M': 26,\n",
       "         '30002': 333,\n",
       "         '01040': 22,\n",
       "         '02176': 66,\n",
       "         '94612': 22,\n",
       "         '42101': 130,\n",
       "         '33775': 22,\n",
       "         '53705': 37,\n",
       "         '59717': 75,\n",
       "         '37901': 254,\n",
       "         '70802': 20,\n",
       "         '13210': 22,\n",
       "         '44405': 21,\n",
       "         '30093': 237,\n",
       "         '94117': 190,\n",
       "         '94143': 232,\n",
       "         '76059': 193,\n",
       "         '10016': 68,\n",
       "         '01331': 21,\n",
       "         '61455': 41,\n",
       "         '45660': 58,\n",
       "         '49938': 44,\n",
       "         '10022': 119,\n",
       "         '98027': 236,\n",
       "         '87501': 311,\n",
       "         '60135': 26,\n",
       "         '85233': 25,\n",
       "         '98133': 76,\n",
       "         '92688': 24,\n",
       "         '44074': 121,\n",
       "         '37411': 58,\n",
       "         '92113': 45,\n",
       "         '99206': 51,\n",
       "         '55116': 368,\n",
       "         '08534': 75,\n",
       "         '78746': 274,\n",
       "         '66046': 66,\n",
       "         '10522': 34,\n",
       "         '02859': 375,\n",
       "         '50670': 33,\n",
       "         '18015': 33,\n",
       "         '37777': 28,\n",
       "         '98117': 196,\n",
       "         '55117': 162,\n",
       "         '94608': 127,\n",
       "         '01824': 53,\n",
       "         '37412': 304,\n",
       "         '01810': 56,\n",
       "         '91335': 22,\n",
       "         '36106': 52,\n",
       "         '43221': 23,\n",
       "         '83702': 639,\n",
       "         '75204': 71,\n",
       "         '85016': 31,\n",
       "         '83686': 448,\n",
       "         '59801': 111,\n",
       "         '10010': 30,\n",
       "         '96819': 149,\n",
       "         '84604': 121,\n",
       "         '60008': 172,\n",
       "         '92374': 319,\n",
       "         '94551': 54,\n",
       "         '84107': 153,\n",
       "         '95129': 68,\n",
       "         '45218': 131,\n",
       "         '44092': 57,\n",
       "         '28480': 25,\n",
       "         '06811': 50,\n",
       "         '10019': 850,\n",
       "         '78213': 22,\n",
       "         '93109': 342,\n",
       "         '03261': 226,\n",
       "         '98225': 203,\n",
       "         '78212': 83,\n",
       "         '92626': 564,\n",
       "         '61755': 57,\n",
       "         '94025': 28,\n",
       "         '44691': 58,\n",
       "         '15222': 51,\n",
       "         '02140': 36,\n",
       "         '58644': 204,\n",
       "         '43215': 32,\n",
       "         '91606': 64,\n",
       "         '29205': 414,\n",
       "         '85258': 31,\n",
       "         '21206': 20,\n",
       "         '55422': 79,\n",
       "         '50311': 62,\n",
       "         '60007': 379,\n",
       "         '11211': 41,\n",
       "         '01602': 101,\n",
       "         '17345': 145,\n",
       "         '98199': 65,\n",
       "         '49705': 44,\n",
       "         '43204': 33,\n",
       "         '85282': 247,\n",
       "         '48076': 51,\n",
       "         '92653': 135,\n",
       "         '55021': 75,\n",
       "         '11758': 540,\n",
       "         '20817': 31,\n",
       "         '48446': 98,\n",
       "         '28018': 206,\n",
       "         '97330': 236,\n",
       "         '06333': 156,\n",
       "         '38115': 63,\n",
       "         '83709': 189,\n",
       "         '53202': 24,\n",
       "         '10021': 116,\n",
       "         '30011': 277,\n",
       "         '31820': 217,\n",
       "         'Y1A6B': 183,\n",
       "         '02918': 33,\n",
       "         '29201': 118,\n",
       "         '60630': 175,\n",
       "         '98102': 23,\n",
       "         '91201': 107,\n",
       "         '02341': 143,\n",
       "         '90804': 101,\n",
       "         '87544': 263,\n",
       "         '05001': 80,\n",
       "         '75218': 133,\n",
       "         '77459': 31,\n",
       "         '93711': 327,\n",
       "         '78628': 43,\n",
       "         '94583': 53,\n",
       "         '60440': 83,\n",
       "         '94708': 35,\n",
       "         '98257': 60,\n",
       "         '55013': 20,\n",
       "         '55409': 268,\n",
       "         '21208': 139,\n",
       "         '93101': 189,\n",
       "         '92121': 231,\n",
       "         '40256': 26,\n",
       "         '37771': 56,\n",
       "         '94618': 79,\n",
       "         '60090': 135,\n",
       "         'V5A2B': 57,\n",
       "         '49428': 47,\n",
       "         '03052': 213,\n",
       "         '02125': 35,\n",
       "         '50112': 279,\n",
       "         '21012': 154,\n",
       "         '55408': 506,\n",
       "         '75006': 102,\n",
       "         '53711': 82,\n",
       "         '94305': 225,\n",
       "         '23092': 37,\n",
       "         '92115': 251,\n",
       "         '20657': 112,\n",
       "         '03869': 242,\n",
       "         '33308': 24,\n",
       "         '28450': 58,\n",
       "         '20707': 194,\n",
       "         '19382': 87,\n",
       "         '21250': 24,\n",
       "         '49508': 40,\n",
       "         '20090': 21,\n",
       "         '26241': 22,\n",
       "         '75230': 20,\n",
       "         '04102': 100,\n",
       "         '10011': 33,\n",
       "         '98038': 30,\n",
       "         '02159': 306,\n",
       "         '10025': 120,\n",
       "         '19711': 54,\n",
       "         '02146': 300,\n",
       "         '12603': 23,\n",
       "         '55320': 49,\n",
       "         '92705': 274,\n",
       "         '94040': 45,\n",
       "         '97408': 30,\n",
       "         '44224': 164,\n",
       "         '12180': 137,\n",
       "         '95821': 26,\n",
       "         '02324': 260,\n",
       "         '80302': 218,\n",
       "         '30078': 163,\n",
       "         '97124': 68,\n",
       "         '05464': 80,\n",
       "         '84302': 133,\n",
       "         '21010': 81,\n",
       "         '60515': 135,\n",
       "         '08052': 162,\n",
       "         '80303': 56,\n",
       "         '14534': 23,\n",
       "         '95123': 197,\n",
       "         '95468': 155,\n",
       "         '22911': 81,\n",
       "         '55443': 30,\n",
       "         '29464': 31,\n",
       "         '62901': 248,\n",
       "         '68147': 84,\n",
       "         '95453': 40,\n",
       "         '30606': 44,\n",
       "         '60005': 357,\n",
       "         '32707': 30,\n",
       "         '14627': 171,\n",
       "         '63132': 20,\n",
       "         '94591': 34,\n",
       "         '48911': 51,\n",
       "         '45680': 25,\n",
       "         '91903': 70,\n",
       "         '20879': 72,\n",
       "         '98281': 36,\n",
       "         '77845': 250,\n",
       "         '53188': 46,\n",
       "         '23227': 52,\n",
       "         '46032': 26,\n",
       "         '27511': 24,\n",
       "         '93063': 225,\n",
       "         '14216': 379,\n",
       "         '01915': 81,\n",
       "         '79508': 166,\n",
       "         '98501': 80,\n",
       "         '93003': 62,\n",
       "         '92093': 84,\n",
       "         '94131': 28,\n",
       "         '97520': 360,\n",
       "         '17961': 47,\n",
       "         '82435': 48,\n",
       "         '29631': 27,\n",
       "         '77073': 20,\n",
       "         'R3T5K': 47,\n",
       "         '90034': 211,\n",
       "         'M4J2K': 25,\n",
       "         '84116': 41,\n",
       "         'M7A1A': 24,\n",
       "         '99687': 148,\n",
       "         '34656': 29,\n",
       "         '02320': 89,\n",
       "         '33716': 90,\n",
       "         '47905': 47,\n",
       "         '31909': 96,\n",
       "         '63044': 236,\n",
       "         '21227': 75,\n",
       "         '77008': 42,\n",
       "         '11201': 108,\n",
       "         '44212': 420,\n",
       "         '80227': 39,\n",
       "         '27705': 103,\n",
       "         '81648': 110,\n",
       "         '01945': 20,\n",
       "         '44134': 89,\n",
       "         '29678': 28,\n",
       "         '14850': 228,\n",
       "         '11787': 27,\n",
       "         '79070': 27,\n",
       "         '08034': 181,\n",
       "         '60187': 45,\n",
       "         '94306': 53,\n",
       "         '20723': 106,\n",
       "         '38866': 20,\n",
       "         '12065': 148,\n",
       "         '95521': 318,\n",
       "         '74101': 104,\n",
       "         '19807': 32,\n",
       "         '55122': 206,\n",
       "         '43085': 25,\n",
       "         '01940': 67,\n",
       "         '23237': 34,\n",
       "         '63645': 42,\n",
       "         '48043': 20,\n",
       "         '91351': 297,\n",
       "         '45810': 58,\n",
       "         '02903': 21,\n",
       "         '78739': 147,\n",
       "         '60657': 685,\n",
       "         '39762': 24,\n",
       "         '10314': 24,\n",
       "         '77380': 224,\n",
       "         '54248': 191,\n",
       "         '51250': 38,\n",
       "         '19341': 158,\n",
       "         '94115': 166,\n",
       "         '78704': 355,\n",
       "         '55412': 142,\n",
       "         '61820': 817,\n",
       "         '98121': 121,\n",
       "         '19102': 23,\n",
       "         '01970': 47,\n",
       "         '60626': 40,\n",
       "         '22906': 35,\n",
       "         '91919': 124,\n",
       "         '32712': 77,\n",
       "         '99835': 49,\n",
       "         '55128': 399,\n",
       "         '54302': 62,\n",
       "         '23509': 75,\n",
       "         '60089': 139,\n",
       "         '90095': 29,\n",
       "         '18053': 40,\n",
       "         '63304': 115,\n",
       "         '45439': 36,\n",
       "         '26506': 71,\n",
       "         '85210': 154,\n",
       "         '60476': 24,\n",
       "         '77042': 130,\n",
       "         '06906': 127,\n",
       "         '21114': 173,\n",
       "         '06365': 157,\n",
       "         '90405': 38,\n",
       "         '54494': 114,\n",
       "         '56321': 33,\n",
       "         '96754': 149,\n",
       "         '91105': 90,\n",
       "         '19146': 236,\n",
       "         '76309': 21,\n",
       "         '27713': 21,\n",
       "         '28814': 34,\n",
       "         '96349': 105,\n",
       "         'N4T1A': 138,\n",
       "         '15203': 221,\n",
       "         '92020': 86,\n",
       "         '54901': 162,\n",
       "         '91206': 224,\n",
       "         '07204': 30,\n",
       "         '44265': 269,\n",
       "         '97208': 22,\n",
       "         '61462': 28,\n",
       "         'V0R2H': 67,\n",
       "         '89104': 31,\n",
       "         '11238': 168,\n",
       "         '55343': 44,\n",
       "         '84105': 93,\n",
       "         '64118': 39,\n",
       "         '94920': 29,\n",
       "         '17331': 42,\n",
       "         '40243': 85,\n",
       "         '16506': 30,\n",
       "         '56567': 21,\n",
       "         '80538': 24,\n",
       "         '95403': 148,\n",
       "         '32114': 38,\n",
       "         '92660': 35,\n",
       "         '29210': 26,\n",
       "         '98072': 73,\n",
       "         '85719': 53,\n",
       "         '93612': 293,\n",
       "         '94403': 22,\n",
       "         '73162': 35,\n",
       "         '80919': 305,\n",
       "         '94720': 108,\n",
       "         '19047': 67,\n",
       "         '70403': 83,\n",
       "         '32303': 33,\n",
       "         '90247': 109,\n",
       "         '21201': 73,\n",
       "         '98405': 20,\n",
       "         '95050': 21,\n",
       "         '47024': 27,\n",
       "         '02113': 129,\n",
       "         '62903': 109,\n",
       "         '06927': 29,\n",
       "         '97007': 38,\n",
       "         '15232': 70,\n",
       "         '12866': 64,\n",
       "         '33066': 23,\n",
       "         '27105': 33,\n",
       "         '80027': 224,\n",
       "         '14211': 41,\n",
       "         '97302': 66,\n",
       "         '68503': 32,\n",
       "         '51157': 105,\n",
       "         '94560': 55,\n",
       "         'K7L5J': 37,\n",
       "         '01960': 65,\n",
       "         '33205': 232,\n",
       "         '01754': 117,\n",
       "         '91040': 39,\n",
       "         '05779': 249,\n",
       "         '55420': 33,\n",
       "         '80913': 231,\n",
       "         '98620': 57,\n",
       "         '77081': 30,\n",
       "         '23322': 27,\n",
       "         '57197': 39,\n",
       "         '48825': 42,\n",
       "         '33755': 358,\n",
       "         '08610': 159,\n",
       "         '85281': 55,\n",
       "         '64131': 239,\n",
       "         '20064': 25,\n",
       "         '34105': 75,\n",
       "         '90036': 28,\n",
       "         '12205': 47,\n",
       "         '19716': 24,\n",
       "         '62522': 26,\n",
       "         '92154': 26,\n",
       "         '30803': 20,\n",
       "         '28806': 183,\n",
       "         '60152': 36,\n",
       "         '12345': 35,\n",
       "         '76234': 20,\n",
       "         '50322': 185,\n",
       "         '05452': 145,\n",
       "         '80228': 28,\n",
       "         '80209': 64,\n",
       "         '73013': 21,\n",
       "         '53066': 106,\n",
       "         '77048': 115,\n",
       "         '33765': 73,\n",
       "         '40205': 28,\n",
       "         '90016': 23,\n",
       "         '11577': 102,\n",
       "         '90019': 267,\n",
       "         '10018': 50,\n",
       "         '01375': 93,\n",
       "         '90814': 57,\n",
       "         '80526': 173,\n",
       "         '95662': 81,\n",
       "         '64153': 54,\n",
       "         '47130': 405,\n",
       "         '02136': 29,\n",
       "         '93055': 27,\n",
       "         '55417': 146,\n",
       "         '53144': 25,\n",
       "         '29646': 209,\n",
       "         '25652': 23,\n",
       "         '78390': 51,\n",
       "         '09645': 21,\n",
       "         '40515': 41,\n",
       "         '04988': 23,\n",
       "         '15017': 20,\n",
       "         '97405': 31,\n",
       "         '47401': 31,\n",
       "         '06492': 39,\n",
       "         '13820': 165,\n",
       "         '97215': 26,\n",
       "         '37725': 21,\n",
       "         '48322': 71,\n",
       "         'V1G4L': 22,\n",
       "         '63021': 294,\n",
       "         '55303': 208,\n",
       "         '92507': 95,\n",
       "         '14085': 43,\n",
       "         '65203': 269,\n",
       "         '44648': 115,\n",
       "         '35802': 89,\n",
       "         '20902': 21,\n",
       "         '74078': 71,\n",
       "         '60302': 20,\n",
       "         '77504': 81,\n",
       "         '33763': 20,\n",
       "         '43017': 259,\n",
       "         '50266': 268,\n",
       "         '40503': 137,\n",
       "         '95316': 102,\n",
       "         '37076': 34,\n",
       "         '45243': 226,\n",
       "         '95823': 59,\n",
       "         '27249': 171,\n",
       "         '03062': 47,\n",
       "         '74075': 245,\n",
       "         '91505': 362,\n",
       "         '33484': 185,\n",
       "         'L1V3W': 124,\n",
       "         '20850': 136,\n",
       "         '61073': 47,\n",
       "         '30350': 40,\n",
       "         '97203': 49,\n",
       "         '70124': 41,\n",
       "         '18505': 45,\n",
       "         '68504': 74,\n",
       "         'N2L5N': 317,\n",
       "         '53210': 98,\n",
       "         '06512': 53,\n",
       "         '08105': 23,\n",
       "         '70116': 103,\n",
       "         '98801': 110,\n",
       "         '29301': 60,\n",
       "         '76201': 132,\n",
       "         '60614': 26,\n",
       "         'E2E3R': 74,\n",
       "         '55428': 120,\n",
       "         '11753': 82,\n",
       "         '33556': 61,\n",
       "         '20006': 35,\n",
       "         '06437': 241,\n",
       "         '53171': 26,\n",
       "         '48105': 184,\n",
       "         '66221': 39,\n",
       "         '55038': 108,\n",
       "         '17036': 20,\n",
       "         '49036': 32,\n",
       "         '78209': 79,\n",
       "         '01701': 20,\n",
       "         '77841': 168,\n",
       "         '33319': 49,\n",
       "         '32789': 142,\n",
       "         '07310': 63,\n",
       "         '90008': 26,\n",
       "         '97229': 22})"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(data['zipcode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_feat_map_process(data):\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_feat_bin_process(data, bins=None, args=None):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_feat_norm_process(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_feat = ['user_id', 'item_id', 'age', 'gender', 'occupation', 'zipcode']\n",
    "label_encoders = {}\n",
    "for fname in sparse_feat:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(data[fname])\n",
    "    data[fname] = le.transform(data[fname])\n",
    "    label_encoders[fname] = (le.classes_.tolist(), dict(zip(le.classes_, le.transform(le.classes_))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['F', 'M'], {'F': 0, 'M': 1})"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoders['gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>unknown</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>...</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>195</td>\n",
       "      <td>241</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>415</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>185</td>\n",
       "      <td>301</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>376</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>311</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>243</td>\n",
       "      <td>50</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>591</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>165</td>\n",
       "      <td>345</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  age  gender  occupation  zipcode  unknown  Action  \\\n",
       "0      195      241   39       1          20      415        0       0   \n",
       "1      185      301   29       0           6        0        0       0   \n",
       "2       21      376   15       1          20      311        0       0   \n",
       "3      243       50   18       1          19      591        0       0   \n",
       "4      165      345   37       1           3      420        0       0   \n",
       "\n",
       "   Adventure  Animation  ...  Fantasy  Film-Noir  Horror  Musical  Mystery  \\\n",
       "0          0          0  ...        0          0       0        0        0   \n",
       "1          0          0  ...        0          1       0        0        1   \n",
       "2          0          0  ...        0          0       0        0        0   \n",
       "3          0          0  ...        0          0       0        0        0   \n",
       "4          0          0  ...        0          0       0        0        0   \n",
       "\n",
       "   Romance  Sci-Fi  Thriller  War  Western  \n",
       "0        0       0         0    0        0  \n",
       "1        0       0         1    0        0  \n",
       "2        0       0         0    0        0  \n",
       "3        1       0         0    1        1  \n",
       "4        0       0         0    0        0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[943,\n",
       " 1682,\n",
       " 61,\n",
       " 2,\n",
       " 21,\n",
       " 795,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_dims = []\n",
    "for col in data.columns:\n",
    "    if col in label_encoders:\n",
    "        feat_dims.append(len(label_encoders[col][0]))\n",
    "    else:\n",
    "        feat_dims.append(1)\n",
    "feat_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3523"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(feat_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id         942\n",
       "item_id        1681\n",
       "age              60\n",
       "gender            1\n",
       "occupation       20\n",
       "zipcode         794\n",
       "unknown           1\n",
       "Action            1\n",
       "Adventure         1\n",
       "Animation         1\n",
       "Children's        1\n",
       "Comedy            1\n",
       "Crime             1\n",
       "Documentary       1\n",
       "Drama             1\n",
       "Fantasy           1\n",
       "Film-Noir         1\n",
       "Horror            1\n",
       "Musical           1\n",
       "Mystery           1\n",
       "Romance           1\n",
       "Sci-Fi            1\n",
       "Thriller          1\n",
       "War               1\n",
       "Western           1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, test_idx = train_test_split(data.index, test_size=0.2)\n",
    "train_data = data.iloc[train_idx.values]\n",
    "test_data = data.iloc[test_idx.values]\n",
    "\n",
    "train_target = target.iloc[train_idx.values]\n",
    "test_target = target.iloc[test_idx.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m        \n",
       "\u001b[0;32mclass\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34mr\"\"\"Dataset wrapping tensors.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Each sample will be retrieved by indexing tensors along the first dimension.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Arguments:\u001b[0m\n",
       "\u001b[0;34m        *tensors (Tensor): tensors that have the same size of the first dimension.\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataset.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.utils.data.TensorDataset??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 26)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 1, ..., 1, 2, 3])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['rating'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CSVDataSet(Dataset):\n",
    "    def __init__(self, data_df, lables):\n",
    "        self.data = data_df.values\n",
    "        data = data['rating']\n",
    "        self.label = .values\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(torch.randn((1000, 10)), torch.randint(10, (1000,))), \n",
    "    batch_size=16,\n",
    "    shuffle=True)\n",
    "vali_loader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(torch.randn((1000, 10)), torch.randint(10, (1000,))), \n",
    "    batch_size=16)\n",
    "\n",
    "dev = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "X, y = next(iter(train_loader))\n",
    "print(X.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ring/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type WideAndDeepModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/Users/ring/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type FeaturesEmbedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/Users/ring/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/Users/ring/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type FeaturesLinear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/Users/ring/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type MultiLayerPerceptron. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/Users/ring/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/Users/ring/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/Users/ring/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ReLU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/Users/ring/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model, 'models/w&d.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%0 : Long(1, 10),\n",
      "      %embedding.embedding.weight : Float(1000, 8),\n",
      "      %linear.bias : Float(1),\n",
      "      %linear.fc.weight : Float(1000, 1),\n",
      "      %mlp.mlp.0.weight : Float(16, 80),\n",
      "      %mlp.mlp.0.bias : Float(16),\n",
      "      %mlp.mlp.3.weight : Float(16, 16),\n",
      "      %mlp.mlp.3.bias : Float(16),\n",
      "      %mlp.mlp.6.weight : Float(1, 16),\n",
      "      %mlp.mlp.6.bias : Float(1)):\n",
      "  %10 : Long(1, 10) = onnx::Constant[value=   0  100  200  300  400  500  600  700  800  900 [ Variable[CPULongType]{1,10} ]]()\n",
      "  %11 : Long(1, 10) = onnx::Add(%0, %10), scope: WideAndDeepModel/FeaturesLinear[linear] # <ipython-input-18-4d85377e88f2>:19:0\n",
      "  %12 : Float(1, 10, 1) = onnx::Gather(%linear.fc.weight, %11), scope: WideAndDeepModel/FeaturesLinear[linear]/Embedding[fc] # /Users/ring/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py:1484:0\n",
      "  %13 : Float(1, 1) = onnx::ReduceSum[axes=[1], keepdims=0](%12), scope: WideAndDeepModel/FeaturesLinear[linear] # <ipython-input-18-4d85377e88f2>:20:0\n",
      "  %14 : Float(1, 1) = onnx::Add(%13, %linear.bias), scope: WideAndDeepModel/FeaturesLinear[linear] # <ipython-input-18-4d85377e88f2>:20:0\n",
      "  %15 : Long(1, 10) = onnx::Constant[value=   0  100  200  300  400  500  600  700  800  900 [ Variable[CPULongType]{1,10} ]]()\n",
      "  %16 : Long(1, 10) = onnx::Add(%0, %15), scope: WideAndDeepModel/FeaturesEmbedding[embedding] # <ipython-input-18-4d85377e88f2>:34:0\n",
      "  %17 : Float(1, 10, 8) = onnx::Gather(%embedding.embedding.weight, %16), scope: WideAndDeepModel/FeaturesEmbedding[embedding]/Embedding[embedding] # /Users/ring/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py:1484:0\n",
      "  %18 : Tensor = onnx::Constant[value= -1  80 [ Variable[CPULongType]{2} ]](), scope: WideAndDeepModel\n",
      "  %19 : Float(1, 80) = onnx::Reshape(%17, %18), scope: WideAndDeepModel # <ipython-input-23-573db22929b0>:19:0\n",
      "  %20 : Float(1, 16) = onnx::Gemm[alpha=1, beta=1, transB=1](%19, %mlp.mlp.0.weight, %mlp.mlp.0.bias), scope: WideAndDeepModel/MultiLayerPerceptron[mlp]/Sequential[mlp]/Linear[0] # /Users/ring/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py:1370:0\n",
      "  %21 : Float(1, 16) = onnx::Relu(%20), scope: WideAndDeepModel/MultiLayerPerceptron[mlp]/Sequential[mlp]/Dropout[2] # /Users/ring/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py:807:0\n",
      "  %22 : Float(1, 16) = onnx::Gemm[alpha=1, beta=1, transB=1](%21, %mlp.mlp.3.weight, %mlp.mlp.3.bias), scope: WideAndDeepModel/MultiLayerPerceptron[mlp]/Sequential[mlp]/Linear[3] # /Users/ring/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py:1370:0\n",
      "  %23 : Float(1, 16) = onnx::Relu(%22), scope: WideAndDeepModel/MultiLayerPerceptron[mlp]/Sequential[mlp]/Dropout[5] # /Users/ring/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py:807:0\n",
      "  %24 : Float(1, 1) = onnx::Gemm[alpha=1, beta=1, transB=1](%23, %mlp.mlp.6.weight, %mlp.mlp.6.bias), scope: WideAndDeepModel/MultiLayerPerceptron[mlp]/Sequential[mlp]/Linear[6] # /Users/ring/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py:1370:0\n",
      "  %25 : Float(1, 1) = onnx::Add(%14, %24), scope: WideAndDeepModel # <ipython-input-23-573db22929b0>:20:0\n",
      "  %26 : Float(1) = onnx::Squeeze[axes=[1]](%25), scope: WideAndDeepModel # <ipython-input-23-573db22929b0>:21:0\n",
      "  %27 : Float(1) = onnx::Sigmoid(%26), scope: WideAndDeepModel # <ipython-input-23-573db22929b0>:21:0\n",
      "  return (%27)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dummy_input = torch.randint(0, 100, (1,10))\n",
    "torch.onnx.export(model, dummy_input, \"models/w&d.onnx\", verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_torch_kernel",
   "language": "python",
   "name": "py3_torch_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
