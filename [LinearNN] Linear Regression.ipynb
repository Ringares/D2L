{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- training process\n",
    "    - defining neural network architectures\n",
    "    - handing data\n",
    "    - specifying loss function: a measure of ftness\n",
    "    - training the model\n",
    "- monitoring\n",
    "- save and load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression 的解析解法\n",
    "\n",
    "$$\n",
    "l^{(i)}(\\mathbf{w}, b)=\\frac{1}{2}\\left(\\hat{y}^{(i)}-y^{(i)}\\right)^{2}\n",
    "$$\n",
    "$$\n",
    "L(\\mathbf{w}, b)=\\frac{1}{n} \\sum_{i=1}^{n} l^{(i)}(\\mathbf{w}, b)=\\frac{1}{n} \\sum_{i=1}^{n} \\frac{1}{2}\\left(\\mathbf{w}^{\\top} \\mathbf{x}^{(i)}+b-y^{(i)}\\right)^{2}\n",
    "$$\n",
    "$$\n",
    "\\mathbf{w}^{*}, b^{*}=\\underset{\\mathbf{w}, b}{\\operatorname{argmin}} L(\\mathbf{w}, b)\n",
    "$$\n",
    "因为线性回归的形式比较简单, 是凸优化问题,\" 其损失函数是严格的凸函数, 有唯一的全局最优解. 通过计算梯度为0, 我们可以求得参数 W 的最优解 (bias 可以通过扩展 x 融入 W 参数中), 是损失函数最小.\n",
    "\n",
    "$$\n",
    "\\mathbf{w}^{*}=\\left(\\mathbf{X}^{\\top} \\mathbf{X}\\right)^{-1} \\mathbf{X}^{\\top} \\mathbf{y}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 梯度下降解法\n",
    "\n",
    "当我们面对高维和非凸损失函数的时候, 我们还可以用梯度下降的方法, 有效的训练我们的模型. 在凸损失面上, 梯度下降算法使我们最终能到达全局最优点; 而对于非凸损失面来说, 我们也能到达相对较好的局部最优点."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "(\\mathbf{w}, b) \\leftarrow(\\mathbf{w}, b)-\\frac{\\eta}{|\\mathcal{B}|} \\sum_{i \\in \\mathcal{B}} \\partial_{(\\mathbf{w}, b)} l^{(i)}(\\mathbf{w}, b)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression 的 Squared Loss 对应的噪声假设"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T14:14:41.839039Z",
     "start_time": "2020-04-30T14:14:41.834311Z"
    }
   },
   "source": [
    "## Linear 具体实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T14:31:39.375244Z",
     "start_time": "2020-04-30T14:31:39.365391Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import sys; sys.path.insert(0, '../')\n",
    "import d2l_utils\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T14:31:39.882523Z",
     "start_time": "2020-04-30T14:31:39.866107Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.1'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "# torch.cuda.manual_seed_all(0)\n",
    "\n",
    "torch.__version__               # PyTorch version\n",
    "# torch.version.cuda              # Corresponding CUDA version\n",
    "# torch.backends.cudnn.version()  # Corresponding cuDNN version\n",
    "# torch.cuda.get_device_name(0)   # GPU type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T14:31:39.978851Z",
     "start_time": "2020-04-30T14:31:39.967539Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 2), (1000,))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_true = 4.2\n",
    "W_true = np.array([2, -3.4])\n",
    "X, y = d2l_utils.synthetic_data(W_true, b_true, num_examples=1000)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T14:31:40.036731Z",
     "start_time": "2020-04-30T14:31:40.030990Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_set(bs):\n",
    "    data_size = len(X)\n",
    "    # random index\n",
    "    index = list(range(data_size))\n",
    "    np.random.shuffle(index)\n",
    "    for i in range(int(data_size/bs)):\n",
    "        batch_index = index[i*bs:(i+1)*bs]\n",
    "        yield X[batch_index], y[batch_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T14:31:40.136912Z",
     "start_time": "2020-04-30T14:31:40.126074Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.47159115 -0.67109709]\n",
      " [ 1.87359844 -0.62738453]\n",
      " [ 1.30957152  1.38793651]\n",
      " [-1.29053027  0.60308994]\n",
      " [ 1.20951341  0.60867067]\n",
      " [ 1.73368678 -0.39315388]\n",
      " [-0.81228793  1.57981897]\n",
      " [-0.07403614  0.17417899]\n",
      " [-1.08244985  1.32969859]\n",
      " [ 1.28990722 -2.62680009]] \n",
      " [ 7.42199552 10.09935919  2.11825675 -0.43454829  4.54963239  9.00763023\n",
      " -2.79516574  3.45236455 -2.4811429  15.69762414]\n"
     ]
    }
   ],
   "source": [
    "for feats, labels in data_set(bs=10): \n",
    "    print(feats, '\\n', labels) \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### numpy 实现 解析解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T14:31:40.287876Z",
     "start_time": "2020-04-30T14:31:40.281522Z"
    }
   },
   "outputs": [],
   "source": [
    "X_ = np.concatenate([np.ones((1000,1)), X], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T14:31:40.392114Z",
     "start_time": "2020-04-30T14:31:40.381223Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.20027501,  2.00031696, -3.39964813])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.inv(X_.T@X_)@(X_.T)@y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### numpy 实现 梯度下降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T14:31:40.554638Z",
     "start_time": "2020-04-30T14:31:40.549104Z"
    }
   },
   "outputs": [],
   "source": [
    "def linear_regression(feats, W, b):\n",
    "    return feats@W+b\n",
    "\n",
    "def square_loss(y_hat, label):\n",
    "    return np.sum((y_hat-label)**2)/2\n",
    "\n",
    "def cal_grad(X, y_hat, label):\n",
    "    return X.T@(y_hat-label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T14:31:40.746566Z",
     "start_time": "2020-04-30T14:31:40.638943Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.20001938]), array([ 2.00001581, -3.39960359]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "W = np.random.randn(2)\n",
    "b = np.zeros(1)\n",
    "epoch = 50\n",
    "bs = 48\n",
    "lr = 1e-2\n",
    "\n",
    "for _ in range(epoch):\n",
    "    for X_batch, y_batch in data_set(bs):\n",
    "        y_hat_batch = linear_regression(X_batch, W, b)\n",
    "        W -= lr*cal_grad(X_batch, y_hat_batch, y_batch)/bs\n",
    "        b -= lr*cal_grad(np.ones(len(X_batch)), y_hat_batch, y_batch)/bs\n",
    "    #print('loss: %s' % square_loss(y_hat_batch, y_batch))\n",
    "\n",
    "b, W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pytorch 自动求导 实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T14:31:41.406433Z",
     "start_time": "2020-04-30T14:31:40.779002Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([4.2003], requires_grad=True),\n",
       " tensor([[ 2.0003],\n",
       "         [-3.3997]], requires_grad=True))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = torch.randn((2,1), dtype=torch.float32, requires_grad=True)\n",
    "b = torch.zeros(1, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "epoch = 50\n",
    "bs = 48\n",
    "lr = 1e-2\n",
    "loss = torch.nn.MSELoss() # lambda y1,y2: ((y1-y2)**2).mean()\n",
    "\n",
    "def linreg(inputs, W, b):\n",
    "    return torch.mm(inputs, W) + b\n",
    "\n",
    "for _ in range(epoch):\n",
    "    for X_batch, labels in data_set(bs):\n",
    "        X_batch = torch.tensor(X_batch, dtype=torch.float32)\n",
    "        labels = torch.tensor(labels, dtype=torch.float32)\n",
    "            \n",
    "        output = linreg(X_batch, W, b)\n",
    "        l = loss(output.reshape(labels.shape), labels)\n",
    "        \n",
    "        l.backward()\n",
    "        W.data -= lr*W.grad\n",
    "        b.data -= lr*b.grad\n",
    "        W.grad.zero_()\n",
    "        b.grad.zero_()\n",
    "    #print('loss: %s' % loss(output, labels).mean().item())\n",
    "b, W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pytorch API 实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T14:31:41.417075Z",
     "start_time": "2020-04-30T14:31:41.409806Z"
    }
   },
   "outputs": [],
   "source": [
    "b_true = 4.2\n",
    "W_true = np.array([2, -3.4])\n",
    "X, y = d2l_utils.synthetic_data(W_true, b_true, num_examples=1000)\n",
    "\n",
    "batch_size = 10\n",
    "data_set = torch.utils.data.TensorDataset(\n",
    "    torch.tensor(X).float(),\n",
    "    torch.tensor(y).float()\n",
    ")\n",
    "data_iter = torch.utils.data.DataLoader(data_set, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T14:31:41.427069Z",
     "start_time": "2020-04-30T14:31:41.421026Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ 1.4374,  1.4527],\n",
      "        [ 1.7666,  1.8294],\n",
      "        [ 0.2987,  1.4632],\n",
      "        [-0.7965, -0.2847],\n",
      "        [ 0.2974, -0.7641],\n",
      "        [ 2.2987, -1.1603],\n",
      "        [ 0.9579, -0.1704],\n",
      "        [ 0.7150,  1.6190],\n",
      "        [ 1.7622,  1.0498],\n",
      "        [-0.6944, -1.8239]]), tensor([ 2.1394,  1.5071, -0.1910,  3.5566,  7.3934, 12.7346,  6.6952,  0.1188,\n",
      "         4.1637,  9.0244])]\n"
     ]
    }
   ],
   "source": [
    "for i in data_iter:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T14:31:41.548874Z",
     "start_time": "2020-04-30T14:31:41.478120Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearNet(\n",
      "  (linear): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "w = torch.empty((2,1), dtype=torch.float32, requires_grad=True)\n",
    "b = torch.empty(1, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "class LinearNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearNet, self).__init__()\n",
    "        self.linear = torch.nn.Linear(in_features=2, out_features=1, bias=True)\n",
    "        torch.nn.init.normal_(self.linear.weight, 0., 0.1)\n",
    "        torch.nn.init.constant_(self.linear.bias, 0.)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "net = LinearNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T14:31:42.657653Z",
     "start_time": "2020-04-30T14:31:42.649240Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.1488, 0.0219]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in net.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T14:17:30.992548Z",
     "start_time": "2020-04-30T14:17:30.978572Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss()\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.03\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.MSELoss()\n",
    "print(loss)\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.03, )\n",
    "print(optimizer)\n",
    "\n",
    "# optimizer =optim.SGD([\n",
    "#     # 如果对某个参数不指定学习率，就使用最外层的默认学习率\n",
    "#     {'params': net.subnet1.parameters()}, # lr=0.03\n",
    "#     {'params': net.subnet2.parameters(), 'lr': 0.01}\n",
    "# ], lr=0.03)net.linear.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T14:17:31.293193Z",
     "start_time": "2020-04-30T14:17:30.996918Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss: 0.000258\n",
      "epoch 2, loss: 0.000158\n",
      "epoch 3, loss: 0.000093\n",
      "epoch 4, loss: 0.000099\n",
      "epoch 5, loss: 0.000117\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 2.0001, -3.4003]]), tensor([4.1999]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    for X, y in data_iter:\n",
    "        optimizer.zero_grad() # 梯度清零，等价于net.zero_grad()\n",
    "        output = net(X)\n",
    "        l = loss(output, y.view(output.shape))\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "    print('epoch %d, loss: %f' % (epoch, l.item()))\n",
    "net.linear.weight.data, net.linear.bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T14:17:31.580417Z",
     "start_time": "2020-04-30T14:17:31.296649Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearNet(\n",
      "  (linear): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n",
      "epoch 1, loss: 0.000667\n",
      "epoch 2, loss: 0.000659\n",
      "epoch 3, loss: 0.000376\n",
      "epoch 4, loss: 0.000209\n",
      "epoch 5, loss: 0.000356\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.9910, -3.3827]]), tensor([4.2025]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = LinearNet() # initiallized\n",
    "print(net)\n",
    "\n",
    "optimizer_w = torch.optim.SGD([net.linear.weight], lr=0.03, weight_decay=0.01)\n",
    "optimizer_b = torch.optim.SGD([net.linear.bias], lr=0.03)\n",
    "\n",
    "num_epochs = 5\n",
    "optimizers = [optimizer_w, optimizer_b]\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    for X, y in data_iter:\n",
    "        for opti in optimizers:\n",
    "            opti.zero_grad()\n",
    "        y_hat = net(X)\n",
    "        l = loss(y_hat, y.view(y_hat.shape))\n",
    "        l.backward()\n",
    "        \n",
    "        for opti in optimizers:\n",
    "            opti.step()\n",
    "    print('epoch %d, loss: %f' % (epoch, l.item()))   \n",
    "net.linear.weight.data, net.linear.bias.data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_torch_kernel",
   "language": "python",
   "name": "py3_torch_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
